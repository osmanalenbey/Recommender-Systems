{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9hiOuzvBR61oj6NJO5p96"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Recommender Systems"],"metadata":{"id":"B2Mmd-EIFc2x"}},{"cell_type":"markdown","source":["In an era of overwhelming choices, recommender systems serve as a crucial tool for matching users with relevant products. The fundamental challenge lies in bridging the gap between two entities that are often semantically different—users and products—by identifying meaningful patterns and relationships. A product can be anything that a user might interact with or consume, such as a movie in a streaming service, a book in an online store, or even a job listing in a recruitment platform. The goal of a recommender system is to predict and suggest the most suitable products for each user, improving both user experience and engagement.\n","\n","To achieve this, recommender systems rely on two major approaches: content-based filtering and collaborative filtering. Content-based filtering uses known attributes of users and products to make recommendations, whereas collaborative filtering learns implicit patterns from past user interactions without requiring predefined features. While content-based filtering aligns well with human intuition—since users and products have explicit characteristics—collaborative filtering captures hidden relationships that may not be immediately obvious.\n","\n","In both approaches, user ratings or interactions serve as labels that guide the learning process, similar to supervised learning. However, unlike typical supervised tasks, the key challenge in recommender systems is that most labels are missing—users only interact with a small fraction of the available products. While missing features are common in machine learning, having missing labels to this extent is less likely, requiring techniques to infer preferences from sparse data."],"metadata":{"id":"vFGQygfdItw8"}},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"oCHHyyx7Fxku"}},{"cell_type":"markdown","source":["The dataset that will be used in this notebook to demonstrate the recommender systems is the MovieLens dataset. The dataset contains rating from 1682 movies rated by 943 users. Since streaming platforms like Netflix is one of the most popular applications of the recommendation systems, this is an appropriate kind of data to make this demonstration."],"metadata":{"id":"TS_H_lH8HXz-"}},{"cell_type":"code","source":["import pandas as pd\n","import zipfile\n","import urllib.request\n","\n","# URL of the dataset\n","url = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n","\n","# Download the zip file\n","urllib.request.urlretrieve(url, \"ml-100k.zip\")\n","\n","# Extract the contents\n","with zipfile.ZipFile(\"ml-100k.zip\", \"r\") as zip_ref:\n","    zip_ref.extractall(\"ml-100k\")"],"metadata":{"id":"I8L3wkR6KWR7","executionInfo":{"status":"ok","timestamp":1742030629437,"user_tz":-60,"elapsed":2187,"user":{"displayName":"Osman Alenbey","userId":"06601504222135124722"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Load the ratings file\n","ratings = pd.read_csv(\"ml-100k/ml-100k/u.data\", sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n","\n","# Load the movie titles\n","movies = pd.read_csv(\"ml-100k/ml-100k/u.item\", sep=\"|\", encoding=\"latin-1\", names=[\"item_id\", \"title\"], usecols=[0, 1])\n","\n","# Merge with ratings\n","ratings = ratings.merge(movies, on=\"item_id\")\n","\n","# Display ratings with movie titles\n","ratings.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"OI_zAGWm_C9D","executionInfo":{"status":"ok","timestamp":1742030642786,"user_tz":-60,"elapsed":223,"user":{"displayName":"Osman Alenbey","userId":"06601504222135124722"}},"outputId":"b4f94b66-65c8-41b6-e0f6-21cd996db103"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   user_id  item_id  rating  timestamp                       title\n","0      196      242       3  881250949                Kolya (1996)\n","1      186      302       3  891717742    L.A. Confidential (1997)\n","2       22      377       1  878887116         Heavyweights (1994)\n","3      244       51       2  880606923  Legends of the Fall (1994)\n","4      166      346       1  886397596         Jackie Brown (1997)"],"text/html":["\n","  <div id=\"df-6a6533d5-3cde-424f-9461-159c4d316189\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>196</td>\n","      <td>242</td>\n","      <td>3</td>\n","      <td>881250949</td>\n","      <td>Kolya (1996)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>186</td>\n","      <td>302</td>\n","      <td>3</td>\n","      <td>891717742</td>\n","      <td>L.A. Confidential (1997)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22</td>\n","      <td>377</td>\n","      <td>1</td>\n","      <td>878887116</td>\n","      <td>Heavyweights (1994)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>244</td>\n","      <td>51</td>\n","      <td>2</td>\n","      <td>880606923</td>\n","      <td>Legends of the Fall (1994)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>166</td>\n","      <td>346</td>\n","      <td>1</td>\n","      <td>886397596</td>\n","      <td>Jackie Brown (1997)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a6533d5-3cde-424f-9461-159c4d316189')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6a6533d5-3cde-424f-9461-159c4d316189 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6a6533d5-3cde-424f-9461-159c4d316189');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-038630d5-9c71-46d5-8055-834235ab6be5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-038630d5-9c71-46d5-8055-834235ab6be5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-038630d5-9c71-46d5-8055-834235ab6be5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"ratings","summary":"{\n  \"name\": \"ratings\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 266,\n        \"min\": 1,\n        \"max\": 943,\n        \"num_unique_values\": 943,\n        \"samples\": [\n          262,\n          136,\n          821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 330,\n        \"min\": 1,\n        \"max\": 1682,\n        \"num_unique_values\": 1682,\n        \"samples\": [\n          1557,\n          808,\n          1618\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5343856,\n        \"min\": 874724710,\n        \"max\": 893286638,\n        \"num_unique_values\": 49282,\n        \"samples\": [\n          889728713,\n          888443306,\n          880605158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1664,\n        \"samples\": [\n          \"House Party 3 (1994)\",\n          \"Three Colors: White (1994)\",\n          \"Fish Called Wanda, A (1988)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["The main dataset consists of the above columns where each user has a unique *user_id* and each movie/media has a unique *item_id* associated. The ratings will be the labels that will be used to train our models. Note that more features can be added using other files in the dataset which will be done in the content-based filtering part. The merging of this additional data will not be done here for simplicity and also keep in mind that they are not relevant for the collaborative filtering part so anyone interested in collaborative filtering can directly skip to that part.\n","\n","Let's convert the above table into a matrix form where rows will correspond to movies and columns to different users."],"metadata":{"id":"Me91FjxnIRRW"}},{"cell_type":"code","source":["# Create a pivot table with movies as rows, users as columns, and ratings as values\n","user_item_matrix = ratings.pivot_table(index=[\"title\", \"item_id\"], columns=\"user_id\", values=\"rating\")\n","user_item_matrix.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"eY2GcZk4CALQ","executionInfo":{"status":"ok","timestamp":1741979202494,"user_tz":-60,"elapsed":553,"user":{"displayName":"Osman Alenbey","userId":"06601504222135124722"}},"outputId":"63f4dca3-13a0-4caa-fdfa-61622bea3b3a"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["user_id                            1    2    3    4    5    6    7    8    \\\n","title                     item_id                                           \n","'Til There Was You (1997) 1300     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n","1-900 (1994)              1353     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n","101 Dalmatians (1996)     225      2.0  NaN  NaN  NaN  2.0  NaN  NaN  NaN   \n","12 Angry Men (1957)       178      5.0  NaN  NaN  NaN  NaN  4.0  4.0  NaN   \n","187 (1997)                330      NaN  NaN  2.0  NaN  NaN  NaN  NaN  NaN   \n","\n","user_id                            9    10   ...  934  935  936  937  938  \\\n","title                     item_id            ...                            \n","'Til There Was You (1997) 1300     NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN   \n","1-900 (1994)              1353     NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN   \n","101 Dalmatians (1996)     225      NaN  NaN  ...  2.0  NaN  NaN  2.0  4.0   \n","12 Angry Men (1957)       178      NaN  5.0  ...  NaN  NaN  NaN  NaN  NaN   \n","187 (1997)                330      NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN   \n","\n","user_id                            939  940  941  942  943  \n","title                     item_id                           \n","'Til There Was You (1997) 1300     NaN  NaN  NaN  NaN  NaN  \n","1-900 (1994)              1353     NaN  NaN  NaN  NaN  NaN  \n","101 Dalmatians (1996)     225      NaN  NaN  NaN  NaN  NaN  \n","12 Angry Men (1957)       178      NaN  NaN  NaN  NaN  NaN  \n","187 (1997)                330      NaN  NaN  NaN  NaN  NaN  \n","\n","[5 rows x 943 columns]"],"text/html":["\n","  <div id=\"df-cfad6c47-5fbb-4733-81cf-b125c680488d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>...</th>\n","      <th>934</th>\n","      <th>935</th>\n","      <th>936</th>\n","      <th>937</th>\n","      <th>938</th>\n","      <th>939</th>\n","      <th>940</th>\n","      <th>941</th>\n","      <th>942</th>\n","      <th>943</th>\n","    </tr>\n","    <tr>\n","      <th>title</th>\n","      <th>item_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>'Til There Was You (1997)</th>\n","      <th>1300</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1-900 (1994)</th>\n","      <th>1353</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>101 Dalmatians (1996)</th>\n","      <th>225</th>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12 Angry Men (1957)</th>\n","      <th>178</th>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>187 (1997)</th>\n","      <th>330</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 943 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfad6c47-5fbb-4733-81cf-b125c680488d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cfad6c47-5fbb-4733-81cf-b125c680488d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cfad6c47-5fbb-4733-81cf-b125c680488d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8abf1cd1-e91a-4872-a4d0-e310ea6b469e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8abf1cd1-e91a-4872-a4d0-e310ea6b469e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8abf1cd1-e91a-4872-a4d0-e310ea6b469e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"user_item_matrix"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["The new matrix shows an important issue in the recommender system data that the data is sparse. Here sparsity does not refer to having a 0 value but instead having no value at all because that user did not watch or rate that movie at all which is generally the case. Thus, although it may seem like we have $1682 \\times 943$ samples at the beginning, only a really small portion of these is available to us. The training algorithms are adjusted to accustomed for the absence of those labels, as well."],"metadata":{"id":"6A3RhvZcKHLk"}},{"cell_type":"markdown","source":["## Content-based filtering"],"metadata":{"id":"od7Xr8k3RgD5"}},{"cell_type":"markdown","source":["In content-based filtering, the goal is to recommend products to users based on their inherent features. We represent users and products as vectors, where each user $j$ has a feature vector $\\mathbf{x}_j^\\text{u}$, and each product $i$ has a feature vector $\\mathbf{x}_i^\\text{p}$. The fundamental idea is to find the best match between these two vectors by measuring their similarity.\n","\n","A common metric for similarity is the **dot product**, which provides a measure of alignment between two vectors. Often, this value is scaled to lie within a specific range, such as $(0,1)$ or $(-1,1)$, where a higher absolute value indicates stronger similarity or relevance in some way. However, this introduces a fundamental challenge: for the dot product to be meaningful, the two vectors must not only have the same dimensionality but also correspond to the same semantic space.\n","\n","In a typical user-product setting, this is rarely the case. Users have features like age, gender, and marital status, while products may have features such as release date, color, and size. These features do not naturally align, making direct comparison through dot products meaningless. To overcome this, we need a transformation that maps both user and product vectors into a common space, ensuring that each dimension corresponds to the same type of semantic meaning—though the level of abstraction may vary. To achieve this, we define transformed feature vectors $\\tilde{\\mathbf{x}}^\\text{u}_{j}$ and $\\tilde{\\mathbf{x}}^\\text{p}_{i}$, which project users and products into a shared latent space where meaningful similarity computations can be performed.\n","\n","In order to train the content-based recommender system, we use a supervised learning approach where the given user ratings serve as ground truth labels. We define $y_{ij}$ as the actual rating provided by user $j$ for product $i$. Our goal is to minimize the squared error between these ratings and the predicted ratings, which are computed as the dot product of the transformed feature vectors, $\\tilde{\\mathbf{x}}^\\text{u}_{j}$ and $\\tilde{\\mathbf{x}}^\\text{p}_{i}$.\n","\n","Since most ratings are missing, our loss function should only consider pairs $(i,j)$ where $y_{ij}$ is defined. Thus, the objective function is:\n","\n","$$\n","J \\left( \\tilde{\\mathbf{x}}^\\text{u}_{j}, \\tilde{\\mathbf{x}}^\\text{p}_{i} \\right) = \\sum_{(i,j) \\in \\mathcal{D}} \\left( y_{ij} - \\tilde{\\mathbf{x}}^\\text{u}_{j} \\cdot \\tilde{\\mathbf{x}}^\\text{p}_{i} \\right)^2\n","$$\n","\n","where $\\mathcal{D}$ represents the set of all pairs $(i,j)$ for which a valid rating $y_{ij}$ is available. This ensures that the loss computation only includes observed ratings and avoids undefined values.\n","\n","While one could attempt to design the transformed feature vectors $\\tilde{\\mathbf{x}}^\\text{u}_{j}$ and $\\tilde{\\mathbf{x}}^\\text{p}_{i}$ manually, this is not a trivial task. Handcrafting such features requires extensive domain expertise and a level of abstract reasoning that is often impractical. Even with deep knowledge of the domain, defining feature transformations that effectively map users and products into a shared space is highly challenging.\n","\n","To overcome this, we can leverage a **deep learning-based approach**, where the feature transformations are not explicitly designed but instead learned automatically. In modern recommender systems, deep learning models are commonly used for this purpose. Specifically, we introduce two neural networks: a **user network** and a **product network**. These networks take raw user and product features as input and output transformed vectors $\\tilde{\\mathbf{x}}^\\text{u}_{j}$ and $\\tilde{\\mathbf{x}}^\\text{p}_{i}$ of identical dimensionality, ensuring that each dimension captures semantically similar information for both users and products.\n","\n","With this learned representation, the dot product $\\tilde{\\mathbf{x}}^\\text{u}_j \\cdot \\tilde{\\mathbf{x}}^\\text{p}_i$ serves as the predicted rating or a score proportional to the user's preference for the given product. By training the networks to minimize the squared error loss, they learn to produce meaningful feature embeddings that improve recommendation accuracy.\n"],"metadata":{"id":"KSe9n5usPc3w"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create figure and axis\n","fig, ax = plt.subplots(figsize=(7, 4))\n","\n","# Define positions\n","x_u_j_pos = (0, 2)  # Original user feature\n","user_net_pos = (2, 2)  # User network\n","x_u_j_tilde_pos = (4, 2)  # Transformed user feature\n","\n","x_p_i_pos = (0, 0)  # Original product feature\n","product_net_pos = (2, 0)  # Product network\n","x_p_i_tilde_pos = (4, 0)  # Transformed product feature\n","\n","dot_product_pos = (6, 1)  # Dot product\n","prediction_pos = (8, 1)  # Prediction\n","\n","# Draw network boxes\n","ax.add_patch(plt.Rectangle((user_net_pos[0]-1.1, user_net_pos[1]-0.5), 2.2, 1, edgecolor='blue', facecolor='lightblue'))\n","ax.add_patch(plt.Rectangle((product_net_pos[0]-1.1, product_net_pos[1]-0.5), 2.2, 1, edgecolor='blue', facecolor='lightblue'))\n","ax.text(user_net_pos[0], user_net_pos[1], \"User Network\", ha='center', va='center', fontsize=10, color='black')\n","ax.text(product_net_pos[0], product_net_pos[1], \"Product Network\", ha='center', va='center', fontsize=10, color='black')\n","\n","# Draw feature labels before networks\n","ax.text(x_u_j_pos[0], x_u_j_pos[1], r\"$\\mathbf{x}^{u}_{j}$\", ha='center', va='center', fontsize=12, color='black')\n","ax.text(x_p_i_pos[0], x_p_i_pos[1], r\"$\\mathbf{x}^{p}_{i}$\", ha='center', va='center', fontsize=12, color='black')\n","\n","# Draw feature labels after networks (tilde versions)\n","ax.text(x_u_j_tilde_pos[0], x_u_j_tilde_pos[1], r\"$\\tilde{\\mathbf{x}}^{u}_{j}$\", ha='center', va='center', fontsize=12, color='black')\n","ax.text(x_p_i_tilde_pos[0], x_p_i_tilde_pos[1], r\"$\\tilde{\\mathbf{x}}^{p}_{i}$\", ha='center', va='center', fontsize=12, color='black')\n","\n","# Draw dot product circle\n","ax.add_patch(plt.Circle(dot_product_pos, 0.2, edgecolor='magenta', facecolor='pink'))\n","ax.text(dot_product_pos[0], dot_product_pos[1], r\"$\\cdot$\", ha='center', va='center', fontsize=14, color='black')\n","\n","# Draw prediction box\n","ax.text(prediction_pos[0], prediction_pos[1], r\"$\\hat{y}_{ij}$\", ha='center', va='center', fontsize=12, color='black')\n","\n","# Draw arrows with rectangular paths\n","def draw_rectangular_arrow(start, end):\n","    \"\"\"Draws an arrow with a rectangular path.\"\"\"\n","    mid_x = (start[0] + end[0]) / 2\n","    if start[1] == end[1]:  # Horizontal movement\n","        ax.plot([start[0], end[0]], [start[1], start[1]], 'k-', lw=1.5)\n","        ax.annotate(\"\", xy=end, xytext=start, arrowprops=dict(arrowstyle=\"->\", color=\"black\", lw=1.5))\n","    else:  # Rectangular movement\n","        ax.plot([start[0], mid_x], [start[1], start[1]], 'k-', lw=1.5)  # Horizontal\n","        ax.plot([mid_x, mid_x], [start[1], end[1]], 'k-', lw=1.5)  # Vertical\n","        ax.plot([mid_x, end[0]], [end[1], end[1]], 'k-', lw=1.5)  # Horizontal\n","        ax.annotate(\"\", xy=end, xytext=(mid_x, end[1]), arrowprops=dict(arrowstyle=\"->\", color=\"black\", lw=1.5))\n","\n","# Connect elements with rectangular arrows\n","draw_rectangular_arrow((0.2,2), (0.9,2))\n","draw_rectangular_arrow((3.1,2), (3.8,2))\n","\n","draw_rectangular_arrow((0.2, 0), (0.9, 0))\n","draw_rectangular_arrow((3.1, 0), (3.8, 0))\n","\n","draw_rectangular_arrow((4.2, 2), (5.8, 1))\n","draw_rectangular_arrow((4.2, 0), (5.8, 1))\n","\n","draw_rectangular_arrow((6.3, 1), (7.6, 1))\n","\n","# Adjust plot settings\n","ax.set_xlim(-1, 9)\n","ax.set_ylim(-1, 3)\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_frame_on(False)\n","\n","# Show plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"Vx6Oy3tjYA3J","executionInfo":{"status":"ok","timestamp":1741968862047,"user_tz":-60,"elapsed":583,"user":{"displayName":"Osman Alenbey","userId":"06601504222135124722"}},"outputId":"7c3b54ad-f038-4fa2-e5f4-a44cbf61877f"},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 700x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["The block diagram to be used in similarity calculation is given above. Note that training will also be done in this configuration, which means there are no separate trainings for user and product networks. Even during inference time, although they can be used individually to generate the vectors  $\\tilde{\\mathbf{x}}^\\text{u}_j$ and $\\tilde{\\mathbf{x}}^\\text{p}_i$, these are not beneficial alone so it is practically not possible as well."],"metadata":{"id":"KY_445Pvb751"}},{"cell_type":"markdown","source":["### Recommendation"],"metadata":{"id":"IgNLXninPk0X"}},{"cell_type":"markdown","source":["Everything so far seems neat and smooth but how the recommendation is done is the actual point here. The similarity of *things* in content-based algorithm is decided by the final score of 2 vectors $\\tilde{\\mathbf{x}}$ , either belonging to a product or a user, put into the dot product operation. The product vectors  $\\tilde{\\mathbf{x}}^\\text{p}$ can be computed instantly once a product is available. Moreover, the dot products between different product vector pairs can also be computed offline and stored which is critical to make fast recommendations once a suitable product has been matched with a user. Then, when a new user is subscribed to a service, the user feature vector $\\tilde{\\mathbf{x}}^\\text{u}$ must be calculated only once.\n","\n","Having the similarity values of product pairs is critical since this means that once a suitable product for a user is found, many more similar things can be recommended almost instantly. In order to make this process efficient, some clustering on the product vectors can be done beforehand and once a user is signed in, instead of calculating the dot product of $\\tilde{\\mathbf{x}}^\\text{u}$ with every available product vector $\\tilde{\\mathbf{x}}^\\text{p}$, this can only be done for the cluster center vectors. If a close match with one of them is found for the user, the other items in that cluster is also most probably a good choice either."],"metadata":{"id":"HckY0RKxPrW4"}},{"cell_type":"markdown","source":["### Implementation"],"metadata":{"id":"6or80mpvcuFG"}},{"cell_type":"code","source":["import torch\n","\n","# ADD PRODUCT FEATURES (products are movies in this case)\n","\n","# Product metadata is available in u.item, so let's extract it:\n","\n","# Load product metadata (genres are in the last columns)\n","product_metadata = pd.read_csv(\"ml-100k/ml-100k/u.item\", sep=\"|\", encoding=\"latin-1\", header=None)\n","product_metadata = pd.concat([product_metadata.iloc[:, 0:3], product_metadata.iloc[:, 5:24]], axis=1)  # Keep only relevant columns\n","\n","# Rename columns (MovieLens 100K format)\n","product_metadata.columns = [\"item_id\", \"title\", \"release_date\"] + [f\"genre_{i}\" for i in range(19)]\n","\n","# Merge metadata with ratings dataset\n","products_with_metadata = ratings.merge(product_metadata, on=\"item_id\")\n","\n","# Genres are stored as one-hot encoded columns. We can use them directly as feature vectors:\n","\n","# Extract only genre columns as features\n","product_features = product_metadata.iloc[:, 3:].values  # 19 genres as one-hot vectors\n","product_features = torch.tensor(product_features, dtype=torch.float32)\n","\n","print(\"Product Feature Shape:\", product_features.shape)  # Should be (num_products, 19)\n","\n","\n","\n","# ADD USER FEATURES\n","\n","# MovieLens 100K includes a user metadata file (u.user)\n","\n","# Load user metadata\n","user_metadata = pd.read_csv(\"ml-100k/ml-100k/u.user\", sep=\"|\", encoding=\"latin-1\", header=None)\n","\n","# Rename columns\n","user_metadata.columns = [\"user_id\", \"age\", \"gender\", \"occupation\", \"zip_code\"]\n","\n","# Drop ZIP code since it's not useful for recommendations\n","user_metadata = user_metadata.drop(columns=[\"zip_code\"])\n","\n","# Convert the categorical features of gender and occupation to one hot vectors\n","\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","# Encode Gender (0 = Female, 1 = Male)\n","user_metadata[\"gender\"] = LabelEncoder().fit_transform(user_metadata[\"gender\"])\n","\n","# One-Hot Encode Occupation\n","occupation_onehot = pd.get_dummies(user_metadata[\"occupation\"], dtype=int)\n","user_metadata = pd.concat([user_metadata.drop(columns=[\"occupation\"]), occupation_onehot], axis=1)\n","user_features = torch.tensor(user_metadata.iloc[:, 1:].values, dtype=torch.float32)  # Drop user_id column\n","\n","print(\"User Features Shape:\", user_features.shape)  # (num_users, feature_dim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5w0UjVvisjJh","executionInfo":{"status":"ok","timestamp":1741979226882,"user_tz":-60,"elapsed":17084,"user":{"displayName":"Osman Alenbey","userId":"06601504222135124722"}},"outputId":"bbe2dfee-7e29-44bd-87cb-adcd1b4a4dcd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Product Feature Shape: torch.Size([1682, 19])\n","User Features Shape: torch.Size([943, 23])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Set random seed for reproducibility\n","def set_random_seed(seed=0):\n","    # random.seed(seed)  # Python random module\n","    np.random.seed(seed)  # NumPy\n","    torch.manual_seed(seed)  # PyTorch CPU\n","    torch.cuda.manual_seed(seed)  # PyTorch GPU (if available)\n","    torch.cuda.manual_seed_all(seed)  # If using multi-GPU\n","    torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior\n","    torch.backends.cudnn.benchmark = False  # Disable optimization that can introduce randomness\n","\n","# Call the function to set the seed\n","set_random_seed(0)\n","\n","# Define Content-Based Filtering Model\n","class ContentBasedFiltering(nn.Module):\n","    def __init__(self, num_user_features, num_movie_features, embedding_dim):\n","        super().__init__()\n","        # User MLP to learn fixed-size embedding\n","        self.user_mlp = nn.Sequential(\n","            nn.Linear(num_user_features, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, embedding_dim)  # Output fixed-size embedding v_u\n","        )\n","\n","        # Product MLP to learn fixed-size embedding\n","        self.product_mlp = nn.Sequential(\n","            nn.Linear(num_movie_features, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, embedding_dim)  # Output fixed-size embedding v_m\n","        )\n","\n","    def forward(self, user_features, user_idx, product_features, product_idx):\n","        # Extract user and movie feature vectors\n","        user_vec = self.user_mlp(user_features[user_idx])\n","        product_vec = self.product_mlp(product_features[product_idx])\n","\n","        # Compute similarity (dot product)\n","        rating_pred = (user_vec * product_vec).sum(dim=1)  # Element-wise product then sum\n","        return rating_pred\n","\n","# Sample dimensions (these would be based on your dataset)\n","num_products, num_users = user_item_matrix.shape\n","embedding_dim = 10  # Final fixed-size embedding for users & products\n","alpha = 0.01  # Learning rate\n","epochs = 1000  # Training iterations\n","\n","# Convert features & ratings to PyTorch tensors\n","ratings_tensor = torch.tensor(user_item_matrix.values, dtype=torch.float32)\n","\n","# Initialize model and optimizer\n","num_user_features = user_features.shape[1]  # Hypothetical user feature size (e.g., age, genre preference)\n","num_product_features = product_features.shape[1]  # Hypothetical product feature size (e.g., genre embeddings, description vectors)\n","model = ContentBasedFiltering(num_user_features, num_product_features, embedding_dim)\n","optimizer = optim.Adam(model.parameters(), lr=alpha)\n","criterion = nn.MSELoss()  # Mean Squared Error loss\n","\n","# Create index pairs for training (only for known ratings)\n","product_idxs, user_idxs  = torch.where(~torch.isnan(ratings_tensor))  # Get valid (user, movie) pairs\n","ratings_vals = ratings_tensor[product_idxs, user_idxs].float()  # Actual ratings\n","\n","# Training Loop\n","for epoch in tqdm(range(epochs)):\n","    optimizer.zero_grad()\n","\n","    predictions = model(user_features, user_idxs, product_features, product_idxs)  # Predicted ratings\n","    loss = criterion(predictions, ratings_vals)  # Compute loss\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n","\n","# Extract learned embeddings\n","learned_user_embeddings = model.user_mlp(user_features).detach().numpy()\n","learned_product_embeddings = model.product_mlp(product_features).detach().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdyjjV8UVH1g","executionInfo":{"status":"ok","timestamp":1741979390191,"user_tz":-60,"elapsed":163292,"user":{"displayName":"Osman Alenbey","userId":"06601504222135124722"}},"outputId":"db62fd9c-85c7-45b6-d0cb-08ecf27a8672"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 1/1000 [00:00<05:43,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 0: Loss = 18.3658\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 102/1000 [00:16<02:23,  6.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Loss = 1.2545\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 202/1000 [00:31<01:54,  6.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 200: Loss = 1.2044\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 302/1000 [00:47<02:01,  5.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 300: Loss = 1.1978\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 402/1000 [01:01<01:52,  5.33it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 400: Loss = 1.1960\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 502/1000 [01:16<01:29,  5.58it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 500: Loss = 1.1946\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 602/1000 [01:30<00:53,  7.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 600: Loss = 1.1947\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 702/1000 [01:47<00:47,  6.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 700: Loss = 1.1927\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 802/1000 [02:03<00:31,  6.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 800: Loss = 1.1926\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 901/1000 [02:18<00:17,  5.72it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 900: Loss = 1.1912\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [02:33<00:00,  6.50it/s]\n"]}]},{"cell_type":"markdown","source":["## Collaborative Filtering"],"metadata":{"id":"4OvNlPYIRdSD"}},{"cell_type":"markdown","source":["In the previous case of content-based filtering, we had vector representations of fixed and equal length for the users and products; and any kind of similarity or relevance was decided based on the numerical closeness of these vectors. While content-based filtering relies on predefined user and product features, collaborative filtering offers an alternative approach: it learns directly from user-product interaction data, without requiring explicit feature definitions. This makes it particularly useful when metadata about users or products is unavailable or insufficient.\n","\n","Let's define a linear estimator for ratings as;\n","\n","$$\n","\\hat{y}_{ij} = \\mathbf{w}_{j}^T \\mathbf{x}_{i} + b_{j}\n","$$\n","\n","where $\\mathbf{w}_{j}^T$ and  $b_{j}$ are user related parameters and $\\mathbf{x}_{i}$ is a product based feature vector. Note that the superscripts $\\text{u}$ and $\\text{p}$ are dropped here because there is a clearer separation of which parameter/variable belongs to what and indices are sufficient for the purposes of this title. Now given the feature vectors $\\mathbf{x}_{i}$ and corresponding ground truth ratings $y_{ij}$, the above problem can be optimized by\n","\n","$$\n","\\min_{\\substack{\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots , \\mathbf{w}_{n_\\text{u}} \\\\ b_{1}, b_{2}, \\dots , b_{n_\\text{u}}}} \\sum_{j=1}^{n_\\text{u}}\\sum_{(i,j) \\in \\mathcal{D}} \\left( y_{ij} - \\left( \\mathbf{w}_{j}^T \\mathbf{x}_{i} + b_{j} \\right) \\right)^2\n","$$\n","\n","This is basically a modified linear regression cost function that is updated for multiple $\\mathbf{w}_{j}$ and  $b_{j}$ candidates and also $\\mathcal{D}$ under the summation showing only the cases that a valid rating is obtained. It is important to know the nuances here that make it differ from a classic linear regression problem but at the end of the day, this is still linear regression that aims to find optimized weights and biases. Let's go to a more interesting case than that now.\n","\n","This time let's assume the optimal weights and $\\mathbf{w}_{j}$ and biases $b_{j}$ are given to us and instead we are trying to find the feature vectors $\\mathbf{x}_{i}$ for these optimal coefficients. Without questioning much, just assume hypothethically this is possible. Then, we need to have optimization problem;\n","\n","$$\n","\\min_{\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots , \\mathbf{x}_{n_\\text{p}}} \\sum_{i=1}^{n_\\text{p}}\\sum_{(i,j) \\in \\mathcal{D}} \\left( y_{ij} - \\left( \\mathbf{w}_{j}^T \\mathbf{x}_{i} + b_{j} \\right) \\right)^2\n","$$\n","\n","This appears like more or less the same problem but the important difference is that the optimization parameters are the vectors themselves. The question at this moment is that how can we know the optimal $\\mathbf{w}_{j}$ and $b_{j}$ to begin with if they had their own optimization problem.\n","\n","It turns out that if we make a total random initialization of paramters $\\mathbf{w}_{j}$ and $b_{j}$; and the features $\\mathbf{x}_{i}$ and then apply the above problems one after the other, on the long run the trend will be in a way that the parameters will be optimized for the vectors and the vectors will be adapted to minimize the overall error, as well. Hence, both will be optimized in a way that will reinforce themselves and a global optimum will be approached. These two can be merged into a single optimization problem as;\n","\n","$$\n","\\min_{\\substack{\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots , \\mathbf{w}_{n_\\text{u}} \\\\ b_{1}, b_{2}, \\dots , b_{n_\\text{u}} \\\\ \\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots , \\mathbf{x}_{n_\\text{p}}}} \\sum_{i=1}^{n_\\text{p}} \\sum_{j=1}^{n_\\text{u}} \\sum_{(i,j) \\in \\mathcal{D}} \\left( y_{ij} - \\left( \\mathbf{w}_{j}^T \\mathbf{x}_{i} + b_{j} \\right) \\right)^2\n","$$\n","\n","This can be seen as a simple problem and indeed it is but what is so remarkable about it is that this is one of the rare cases that a learning mechanism does not only find optimal coefficients for a task but it also generates the optimal features to achieve it without even starting from less useful features and only a random initialization is sufficient. The variants of the algorithm can be done to make the initialization of $\\mathbf{x}_{i}$'s from known features of the products but important point is that it is not obligatory and an optimization is possible starting from scratch."],"metadata":{"id":"JMrU3Uu7sIvE"}},{"cell_type":"markdown","source":["### Cold Start Problem"],"metadata":{"id":"fsErkhVB743a"}},{"cell_type":"markdown","source":["One of the drawbacks of the collaborative filtering is that it does not allow for a simple assesment of a previously unknown user defined by the tuple $(\\mathbf{w}_{j}, b_{j})$ and unknown product defined by feature vector $\\mathbf{x}_{i}$. Both of these things have to go through some sort of training process to be meaningful. This was not the case in the content-based filtering because after doing the initial learning with a training set, we have well defined blocks of user and product networks which can be used to convert any new input into useful representations. This is called the **cold-start problem** and is an obstacle to instant handling of a newly joined user to a service or a newly added product in that service."],"metadata":{"id":"O8weHm1G77pT"}},{"cell_type":"markdown","source":["### Recommendation"],"metadata":{"id":"KWCb8DKrNKFr"}},{"cell_type":"markdown","source":["As in the case of content-based filtering the similar products can be defined based on the closeness of the feature vectors $\\mathbf{x}_{i}$. In a similar manner, they can also be grouped into clusters and once a user is associated with the cluster center vector or any particular product within that cluster, other items in the cluster will also be nice recommendation choices, as well.\n","\n","Unlike the content-based filtering, there is no direct notion of a user vector in collaborative filtering. The closest thing is the linear operation between the tuple $(\\mathbf{w}_{j}, b_{j})$ and the product vector $\\mathbf{x}_{i}$ can be considered as a dot product, as well. The major difference is that those $(\\mathbf{w}_{j}, b_{j})$ tuples for a user are directly generated by the ratings of that user and are not available until a few ratings are done, which was the reason for the cold-start problem discussed. Thus, the first recommendations to that user can be done either by totally randomly, by using other features of the user like demographic information, using a mean normalization technique so that the user will be assigned a tuple $(\\mathbf{w}_{j}, b_{j})$ such that he/she made ratings as the average of actual ratings of the other users."],"metadata":{"id":"jAV8PfpsNLhq"}},{"cell_type":"markdown","source":["### Implementation"],"metadata":{"id":"HmOHY6WH4wcM"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Set random seed for reproducibility\n","def set_random_seed(seed=0):\n","    # random.seed(seed)  # Python random module\n","    np.random.seed(seed)  # NumPy\n","    torch.manual_seed(seed)  # PyTorch CPU\n","    torch.cuda.manual_seed(seed)  # PyTorch GPU (if available)\n","    torch.cuda.manual_seed_all(seed)  # If using multi-GPU\n","    torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior\n","    torch.backends.cudnn.benchmark = False  # Disable optimization that can introduce randomness\n","\n","# Call the function to set the seed\n","set_random_seed(0)\n","\n","# Convert ratings DataFrame to NumPy and handle NaNs\n","ratings = user_item_matrix.values\n","mask = ~np.isnan(ratings)  # Boolean mask for known ratings\n","ratings = np.nan_to_num(ratings)  # Convert NaNs to 0 for PyTorch\n","\n","# # Parameters\n","# num_users = user_item_matrix.shape[1]  # Number of users\n","# num_movies = user_item_matrix.shape[0]  # Number of movies\n","num_products, num_users = user_item_matrix.shape\n","num_features = 10  # Number of latent factors\n","alpha = 0.1  # Learning rate\n","epochs = 1000  # Number of training iterations\n","\n","# Convert to PyTorch tensors\n","ratings_tensor = torch.tensor(ratings, dtype=torch.float32)\n","mask_tensor = torch.tensor(mask, dtype=torch.float32)\n","\n","# Define Collaborative Filtering Model\n","class CollaborativeFiltering(nn.Module):\n","    def __init__(self, num_users, num_products, num_features):\n","        super().__init__()\n","        self.user_features = nn.Parameter(torch.rand(num_users, num_features))  # User feature matrix (w)\n","        self.product_features = nn.Parameter(torch.rand(num_products, num_features))  # Product feature matrix (x)\n","        self.user_bias = nn.Parameter(torch.rand(num_users))  # User biases (b)\n","\n","    def forward(self):\n","        return torch.matmul(self.product_features, self.user_features.T) + self.user_bias  # Predicted ratings\n","\n","# Initialize model and optimizer\n","model = CollaborativeFiltering(num_users, num_products, num_features)\n","optimizer = optim.Adam(model.parameters(), lr=alpha)\n","\n","# Loss function (MSE but applied only to known ratings)\n","def masked_loss(pred, true, mask):\n","    return torch.sum(((pred - true) * mask) ** 2) / torch.sum(mask)\n","\n","# Training Loop\n","for epoch in tqdm(range(epochs)):\n","    optimizer.zero_grad()\n","    predictions = model()\n","    loss = masked_loss(predictions, ratings_tensor, mask_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n","\n","# Extract learned features\n","learned_user_features = model.user_features.detach().numpy()\n","learned_product_features = model.product_features.detach().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xrr1r4q4PoBn","executionInfo":{"status":"ok","timestamp":1741978174958,"user_tz":-60,"elapsed":44862,"user":{"displayName":"Osman Alenbey","userId":"06601504222135124722"}},"outputId":"3850a399-04ff-4842-fd7c-fb59d1a527b1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 4/1000 [00:00<00:58, 17.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 0: Loss = 2.1201\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█         | 107/1000 [00:03<00:26, 33.35it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Loss = 0.4926\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 207/1000 [00:06<00:24, 32.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 200: Loss = 0.4618\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 305/1000 [00:10<00:21, 31.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 300: Loss = 0.4527\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 405/1000 [00:13<00:18, 31.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 400: Loss = 0.4487\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 505/1000 [00:16<00:15, 32.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 500: Loss = 0.4466\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 603/1000 [00:20<00:17, 22.69it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 600: Loss = 0.4452\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 704/1000 [00:23<00:09, 31.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 700: Loss = 0.4444\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 804/1000 [00:26<00:06, 32.42it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 800: Loss = 0.4436\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 904/1000 [00:29<00:03, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 900: Loss = 0.4430\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [00:33<00:00, 30.04it/s]\n"]}]}]}